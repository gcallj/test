{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gcallj/test/blob/main/Copy%20of%20STOCK_ETL_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "77uYBRWbYufA",
        "outputId": "0799c90e-daaa-48c6-914a-57ba3429c4a5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for ta (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip -q install lightgbm pyarrow fastparquet tqdm_joblib imbalanced-learn ta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BXcYIBB46rF4",
        "outputId": "cee6f164-45ab-46de-cc98-b9639034c2d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Baixando cotações do Yahoo Finance...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:yfinance:HTTP Error 404: {\"quoteSummary\":{\"result\":null,\"error\":{\"code\":\"Not Found\",\"description\":\"Quote not found for symbol: MRFG3.SA\"}}}\n",
            "ERROR:yfinance:\n",
            "12 Failed downloads:\n",
            "ERROR:yfinance:['MRFG3.SA', 'CIEL3.SA', 'BRFS3.SA', 'VVAR3.SA', 'XAGEUR', 'JBSS3.SA', 'LAME4.SA', 'CCRO3.SA', 'GOLL4.SA', 'CESP6.SA', 'NTCO3.SA', 'XAUEUR']: YFTzMissingError('possibly delisted; no timezone found')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Período: 2005-01-03 → 2025-12-31\n",
            "Tickers com dados: 147\n",
            "Gerando features e targets por ticker...\n",
            "Gerando features e targets por ticker...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 147/147 [05:31<00:00,  2.26s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tickers processados: 147 | Motivos de skip: {}\n",
            "[Feature reduction] columns: 24696 → 14276 (57.8% kept)\n",
            "Saved FULL:     drive/My Drive/Colab Notebooks/stock/expanded_stock.parquet  shape=(6656, 25284)\n",
            "Saved REDUCED:  drive/My Drive/Colab Notebooks/stock/expanded_stock_reduced.parquet  shape=(6656, 14864)\n",
            "X full: (6656, 24696)\n",
            "y: (6656, 588)\n",
            "X_reduced: (6656, 14276)\n",
            "Min/median/max kept per ticker: 17 103.0 126\n",
            "Processed tickers: 147\n",
            "Missing tickers: 0\n"
          ]
        }
      ],
      "source": [
        "!pip -q install lightgbm pyarrow fastparquet tqdm imbalanced-learn ta\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import yfinance as yf\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import ta  # technical analysis\n",
        "from google.colab import drive\n",
        "\n",
        "# ============================\n",
        "# Configurações gerais\n",
        "# ============================\n",
        "START_DATE = \"2005-01-01\"\n",
        "\n",
        "# Permite preencher lacunas de FEATURES com bfill (útil p/ calendários diferentes).\n",
        "# Isto pode introduzir leakage \"quando inevitável\".\n",
        "ALLOW_BFILL_EXOGENOUS = False\n",
        "\n",
        "# Defasagem das FEATURES (1 evita leakage trivial; 0 permite mais vazamento).\n",
        "SHIFT_FEATURES = 0\n",
        "\n",
        "# Médias móveis a usar (manteremos TODOS cruzamentos slow > fast)\n",
        "AVERAGES = [1, 2, 5, 10, 15, 20, 25, 50, 100]\n",
        "\n",
        "# Horizonte para cálculo de alvos\n",
        "HORIZON = 90\n",
        "UP_THR = 0.30   # +30%\n",
        "DD_THR = -0.10  # -10%\n",
        "\n",
        "\n",
        "SAVE_PARQUET = True\n",
        "SAVE_CSV_FALLBACK = False\n",
        "OUTPUT_PATH = \"drive/My Drive/Colab Notebooks/stock/expanded_stock.parquet\"\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# ============================\n",
        "# Listas de tickers\n",
        "# ============================\n",
        "ibovespa_tickers = [\n",
        "    'ABEV3.SA', 'B3SA3.SA', 'BBAS3.SA', 'BBDC4.SA', 'BBSE3.SA', 'BRFS3.SA', 'BRKM5.SA', 'CCRO3.SA',\n",
        "    'CIEL3.SA', 'CMIG4.SA', 'CSAN3.SA', 'CSNA3.SA', 'CVCB3.SA', 'CYRE3.SA', 'ECOR3.SA', 'EGIE3.SA', 'ELET3.SA', 'EMBR3.SA',\n",
        "    'ENGI11.SA', 'EQTL3.SA', 'EVEN3.SA', 'FIBR3.SA', 'GGBR4.SA', 'HAPV3.SA', 'ITUB4.SA', 'JBSS3.SA',\n",
        "    'JHSF3.SA', 'LAME4.SA', 'LOGG3.SA', 'LREN3.SA', 'MULT3.SA', 'NATU3.SA', 'MRFG3.SA', 'MOVI3.SA',\n",
        "    'MYPK3.SA', 'MDIA3.SA', 'IRBR3.SA', 'NTCO3.SA', 'PETR3.SA', 'PETR4.SA', 'PRIO3.SA', 'RADL3.SA',\n",
        "    'RAIL3.SA', 'RENT3.SA', 'RAIZ4.SA', 'SBSP3.SA', 'SANB3.SA', 'SAPR3.SA', 'SUZB3.SA', 'TCSA3.SA',\n",
        "    'VIVA3.SA', 'AZUL4.SA', 'GOLL4.SA', 'WEGE3.SA','BBDC3.SA', 'VVAR3.SA', 'BEEF3.SA', 'CESP6.SA',\n",
        "    'USIM5.SA', 'VALE3.SA', 'POMO4.SA', 'LEVE3.SA', 'TUPY3.SA', 'RAPT4.SA', 'ROMI3.SA'\n",
        "]\n",
        "\n",
        "fii_tickers = [\n",
        "    'MXRF11.SA','HGLG11.SA','KNRI11.SA','VISC11.SA','XPLG11.SA','VILG11.SA','BTLG11.SA',\n",
        "    'BRCO11.SA','GGRC11.SA','LVBI11.SA','XPML11.SA','HSML11.SA',\n",
        "    'BRCR11.SA','HGRE11.SA','PVBI11.SA','RCRB11.SA','VINO11.SA',\n",
        "    'ALZR11.SA','TRXF11.SA','RBVA11.SA','RBRP11.SA',\n",
        "    'KNCR11.SA','KNHY11.SA','KNSC11.SA','CPTS11.SA','HCTR11.SA','IRDM11.SA','URPR11.SA',\n",
        "    'OUJP11.SA','VRTA11.SA','HGCR11.SA','DEVA11.SA','RBRR11.SA',\n",
        "    'HFOF11.SA','KFOF11.SA','XPSF11.SA','RBRF11.SA','VGHF11.SA',\n",
        "]\n",
        "\n",
        "global_indices = [\n",
        "    '^GSPC', '^DJI', '^IXIC', '^FTSE', '^FCHI', '^GDAXI', '^N225', '^HSI', '^AXJO', '^BSESN', '^SSE', '^JKSE', '^BVSP'\n",
        "]\n",
        "\n",
        "currency_commodity_tickers = [\n",
        "    'UUP','FXE','FXY','GLD','USO',\n",
        "    'EURUSD=X','GBPUSD=X','CNYUSD=X','AUDUSD=X','CHFUSD=X','BRLUSD=X','MXNUSD=X',\n",
        "    'BTC-USD','ETH-USD','DOGE-USD','LTC-USD','SOL-USD',\n",
        "    'CL=F','GC=F','NG=F','HG=F','ZC=F','HE=F','ZW=F','S=F','BZ=F',\n",
        "    'XAUEUR','XAGEUR','COPX','MGC=F','HO=F'\n",
        "]\n",
        "\n",
        "ALL_TICKERS = ibovespa_tickers + fii_tickers + global_indices + currency_commodity_tickers\n",
        "\n",
        "# ============================\n",
        "# Utilidades de preenchimento/casting\n",
        "# ============================\n",
        "def fill_100pct(df: pd.DataFrame, allow_bfill=True) -> pd.DataFrame:\n",
        "    \"\"\"Garante 100% preenchido: Inf->NaN, ffill, bfill opcional, e NaN restantes->0.\"\"\"\n",
        "    df = df.replace([np.inf, -np.inf], np.nan)\n",
        "    df = df.ffill()\n",
        "    if allow_bfill:\n",
        "        df = df.bfill()\n",
        "    # Se alguma coluna ficou toda NaN (pode ocorrer em padrões), zera\n",
        "    all_nan_cols = df.columns[df.isna().all()].tolist()\n",
        "    if all_nan_cols:\n",
        "        df[all_nan_cols] = 0.0\n",
        "    # NaN remanescentes -> 0\n",
        "    df = df.fillna(0.0)\n",
        "    return df\n",
        "\n",
        "def cast_int8_multi(df: pd.DataFrame, prefixes=(), suffixes=()):\n",
        "    if not isinstance(df.columns, pd.MultiIndex):\n",
        "        return df\n",
        "\n",
        "    level0 = pd.Index(df.columns.get_level_values(0).astype(str))\n",
        "    mask = np.zeros(len(level0), dtype=bool)\n",
        "\n",
        "    if prefixes:\n",
        "        starts = level0.str.startswith(prefixes)          # array-like\n",
        "        mask = np.logical_or(mask, np.asarray(starts, dtype=bool))\n",
        "\n",
        "    if suffixes:\n",
        "        ends = level0.str.endswith(suffixes)              # array-like\n",
        "        mask = np.logical_or(mask, np.asarray(ends, dtype=bool))\n",
        "\n",
        "    cols = df.columns[mask]\n",
        "    if len(cols):\n",
        "        df = df.copy()\n",
        "        df.loc[:, cols] = df.loc[:, cols].astype('int8', copy=False)\n",
        "    return df\n",
        "\n",
        "# ============================\n",
        "# Download dos dados\n",
        "# ============================\n",
        "print(\"Baixando cotações do Yahoo Finance...\")\n",
        "data = yf.download(\n",
        "    ALL_TICKERS,\n",
        "    start=START_DATE,\n",
        "    group_by='column',\n",
        "    auto_adjust=True,\n",
        "    progress=False,\n",
        "    threads=True\n",
        ")\n",
        "\n",
        "# Somente colunas OHLCV relevantes e limpeza de levels\n",
        "allowed_columns = ['Open','High','Low','Close','Adj Close','Volume']\n",
        "data = data.loc[:, data.columns.get_level_values(0).isin(allowed_columns)].copy()\n",
        "data.columns = data.columns.remove_unused_levels()\n",
        "\n",
        "# Forward-fill para alinhar calendários; (bfill só nas FEATURES mais adiante)\n",
        "data = data.ffill()\n",
        "\n",
        "# Tickers efetivamente presentes\n",
        "tickers = np.unique(data.columns.get_level_values(1))\n",
        "print(f\"Período: {data.index.min().date()} → {data.index.max().date()}\")\n",
        "print(f\"Tickers com dados: {len(tickers)}\")\n",
        "\n",
        "# ============================\n",
        "# Funções de padrões (com prefixos)\n",
        "# ============================\n",
        "def detect_head_shoulder(df, window=3, prefix=\"hs_\"):\n",
        "    out = pd.DataFrame(index=df.index)\n",
        "    out[prefix+'high_roll_max'] = df['High'].rolling(window).max()\n",
        "    out[prefix+'low_roll_min']  = df['Low'].rolling(window).min()\n",
        "    mask_hs  = ((out[prefix+'high_roll_max'] > df['High'].shift(1)) &\n",
        "                (out[prefix+'high_roll_max'] > df['High'].shift(-1)) &\n",
        "                (df['High'] < df['High'].shift(1)) &\n",
        "                (df['High'] < df['High'].shift(-1)))\n",
        "    mask_inv = ((out[prefix+'low_roll_min'] < df['Low'].shift(1)) &\n",
        "                (out[prefix+'low_roll_min'] < df['Low'].shift(-1)) &\n",
        "                (df['Low'] > df['Low'].shift(1)) &\n",
        "                (df['Low'] > df['Low'].shift(-1)))\n",
        "    out[prefix+'pattern'] = 0\n",
        "    out.loc[mask_hs,  prefix+'pattern'] = 1\n",
        "    out.loc[mask_inv, prefix+'pattern'] = -1\n",
        "    return out\n",
        "\n",
        "def detect_multiple_tops_bottoms(df, window=3, prefix=\"mtb_\"):\n",
        "    out = pd.DataFrame(index=df.index)\n",
        "    out[prefix+'high_roll_max']  = df['High'].rolling(window).max()\n",
        "    out[prefix+'low_roll_min']   = df['Low'].rolling(window).min()\n",
        "    out[prefix+'close_roll_max'] = df['Close'].rolling(window).max()\n",
        "    out[prefix+'close_roll_min'] = df['Close'].rolling(window).min()\n",
        "    mask_top    = (out[prefix+'high_roll_max'] >= df['High'].shift(1)) & (out[prefix+'close_roll_max'] < df['Close'].shift(1))\n",
        "    mask_bottom = (out[prefix+'low_roll_min']  <= df['Low'].shift(1))  & (out[prefix+'close_roll_min']  > df['Close'].shift(1))\n",
        "    out[prefix+'pattern'] = 0\n",
        "    out.loc[mask_top,    prefix+'pattern'] = 1\n",
        "    out.loc[mask_bottom, prefix+'pattern'] = -1\n",
        "    return out\n",
        "\n",
        "def calculate_support_resistance(df, window=3, prefix=\"sr_\"):\n",
        "    out = pd.DataFrame(index=df.index)\n",
        "    mean_high = df['High'].rolling(window).mean()\n",
        "    std_high  = df['High'].rolling(window).std()\n",
        "    mean_low  = df['Low'].rolling(window).mean()\n",
        "    std_low   = df['Low'].rolling(window).std()\n",
        "    out[prefix+'support']     = mean_low - 2*std_low\n",
        "    out[prefix+'resistance']  = mean_high + 2*std_high\n",
        "    out[prefix+'diff_support']    = df['Close'] - out[prefix+'support']\n",
        "    out[prefix+'diff_resistance'] = out[prefix+'resistance'] - df['Close']\n",
        "    return out\n",
        "\n",
        "def detect_triangle_pattern(df, window=3, prefix=\"tri_\"):\n",
        "    out = pd.DataFrame(index=df.index)\n",
        "    out[prefix+'high_roll_max'] = df['High'].rolling(window).max()\n",
        "    out[prefix+'low_roll_min']  = df['Low'].rolling(window).min()\n",
        "    mask_asc  = (out[prefix+'high_roll_max'] >= df['High'].shift(1)) & (out[prefix+'low_roll_min'] <= df['Low'].shift(1)) & (df['Close'] > df['Close'].shift(1))\n",
        "    mask_desc = (out[prefix+'high_roll_max'] <= df['High'].shift(1)) & (out[prefix+'low_roll_min'] >= df['Low'].shift(1)) & (df['Close'] < df['Close'].shift(1))\n",
        "    out[prefix+'pattern'] = 0\n",
        "    out.loc[mask_asc,  prefix+'pattern'] = 1\n",
        "    out.loc[mask_desc, prefix+'pattern'] = -1\n",
        "    return out\n",
        "\n",
        "def detect_wedge(df, window=3, prefix=\"wed_\"):\n",
        "    out = pd.DataFrame(index=df.index)\n",
        "    out[prefix+'high_roll_max'] = df['High'].rolling(window).max()\n",
        "    out[prefix+'low_roll_min']  = df['Low'].rolling(window).min()\n",
        "    trend_high = df['High'].rolling(window).apply(lambda x: 1 if (x[-1]-x[0])>0 else (-1 if (x[-1]-x[0])<0 else 0), raw=True)\n",
        "    trend_low  = df['Low'].rolling(window).apply(lambda x: 1 if (x[-1]-x[0])>0 else (-1 if (x[-1]-x[0])<0 else 0), raw=True)\n",
        "    mask_up   = (out[prefix+'high_roll_max'] >= df['High'].shift(1)) & (out[prefix+'low_roll_min'] <= df['Low'].shift(1)) & (trend_high == 1) & (trend_low == 1)\n",
        "    mask_down = (out[prefix+'high_roll_max'] <= df['High'].shift(1)) & (out[prefix+'low_roll_min'] >= df['Low'].shift(1)) & (trend_high == -1) & (trend_low == -1)\n",
        "    out[prefix+'pattern'] = 0\n",
        "    out.loc[mask_up,   prefix+'pattern'] = 1\n",
        "    out.loc[mask_down, prefix+'pattern'] = -1\n",
        "    return out\n",
        "\n",
        "def detect_channel(df, window=3, prefix=\"chan_\", channel_range=0.1):\n",
        "    out = pd.DataFrame(index=df.index)\n",
        "    out[prefix+'high_roll_max'] = df['High'].rolling(window).max()\n",
        "    out[prefix+'low_roll_min']  = df['Low'].rolling(window).min()\n",
        "    trend_high = df['High'].rolling(window).apply(lambda x: 1 if (x[-1]-x[0])>0 else (-1 if (x[-1]-x[0])<0 else 0), raw=True)\n",
        "    trend_low  = df['Low'].rolling(window).apply(lambda x: 1 if (x[-1]-x[0])>0 else (-1 if (x[-1]-x[0])<0 else 0), raw=True)\n",
        "    width = out[prefix+'high_roll_max'] - out[prefix+'low_roll_min']\n",
        "    mid   = (out[prefix+'high_roll_max'] + out[prefix+'low_roll_min'])/2\n",
        "    mask_up   = (out[prefix+'high_roll_max'] >= df['High'].shift(1)) & (out[prefix+'low_roll_min'] <= df['Low'].shift(1)) & (width <= channel_range*mid) & (trend_high==1) & (trend_low==1)\n",
        "    mask_down = (out[prefix+'high_roll_max'] <= df['High'].shift(1)) & (out[prefix+'low_roll_min'] >= df['Low'].shift(1)) & (width <= channel_range*mid) & (trend_high==-1) & (trend_low==-1)\n",
        "    out[prefix+'pattern'] = 0\n",
        "    out.loc[mask_up,   prefix+'pattern'] = 1\n",
        "    out.loc[mask_down, prefix+'pattern'] = -1\n",
        "    return out\n",
        "\n",
        "def detect_double_top_bottom(df, window=3, threshold=0.05, prefix=\"dbl_\"):\n",
        "    out = pd.DataFrame(index=df.index)\n",
        "    out[prefix+'high_roll_max'] = df['High'].rolling(window).max()\n",
        "    out[prefix+'low_roll_min']  = df['Low'].rolling(window).min()\n",
        "    mask_top = (out[prefix+'high_roll_max'] >= df['High'].shift(1)) & (out[prefix+'high_roll_max'] >= df['High'].shift(-1)) & \\\n",
        "               (df['High'] < df['High'].shift(1)) & (df['High'] < df['High'].shift(-1)) & \\\n",
        "               ((df['High'].shift(1)-df['Low'].shift(1)) <= threshold*(df['High'].shift(1)+df['Low'].shift(1))/2) & \\\n",
        "               ((df['High'].shift(-1)-df['Low'].shift(-1)) <= threshold*(df['High'].shift(-1)+df['Low'].shift(-1))/2)\n",
        "    mask_bottom = (out[prefix+'low_roll_min'] <= df['Low'].shift(1)) & (out[prefix+'low_roll_min'] <= df['Low'].shift(-1)) & \\\n",
        "                  (df['Low'] > df['Low'].shift(1)) & (df['Low'] > df['Low'].shift(-1)) & \\\n",
        "                  ((df['High'].shift(1)-df['Low'].shift(1)) <= threshold*(df['High'].shift(1)+df['Low'].shift(1))/2) & \\\n",
        "                  ((df['High'].shift(-1)-df['Low'].shift(-1)) <= threshold*(df['High'].shift(-1)+df['Low'].shift(-1))/2)\n",
        "    out[prefix+'pattern'] = 0\n",
        "    out.loc[mask_top,    prefix+'pattern'] = 1\n",
        "    out.loc[mask_bottom, prefix+'pattern'] = -1\n",
        "    return out\n",
        "\n",
        "def detect_trendline(df, window=2, prefix=\"trend_\"):\n",
        "    out = pd.DataFrame(index=df.index)\n",
        "    slope = np.zeros(len(df), dtype='float64')\n",
        "    intercept = np.zeros(len(df), dtype='float64')\n",
        "    idx = np.arange(len(df))\n",
        "    close = df['Close'].values\n",
        "    for i in range(window, len(df)):\n",
        "        x = idx[i-window:i].astype(float)\n",
        "        y = close[i-window:i]\n",
        "        A = np.vstack([x, np.ones_like(x)]).T\n",
        "        m, c = np.linalg.lstsq(A, y, rcond=None)[0]\n",
        "        slope[i] = m\n",
        "        intercept[i] = c\n",
        "    out[prefix+'slope'] = slope\n",
        "    out[prefix+'intercept'] = intercept\n",
        "    x_now = idx.astype(float)\n",
        "    y_line = slope * x_now + intercept\n",
        "    # Estes dois podem ficar inteiros NaN; trataremos depois com fill_100pct\n",
        "    out[prefix+'support2'] = np.where(slope>0, y_line, np.nan)\n",
        "    out[prefix+'resistance2'] = np.where(slope<0, y_line, np.nan)\n",
        "    out[prefix+'diff_support2'] = df['Close'] - out[prefix+'support2']\n",
        "    out[prefix+'diff_resistance2'] = out[prefix+'resistance2'] - df['Close']\n",
        "    return out\n",
        "# ============================\n",
        "# New PATH-AWARE targets (split)\n",
        "# ============================\n",
        "def make_targets_up_down(df, horizon=30, up_thr=0.20, dd_thr=-0.05,\n",
        "                         name_up='target_up20', name_dd='target_dd5',\n",
        "                         keep_order=False, name_order='target_up_before_dd'):\n",
        "    \"\"\"\n",
        "    For each day t:\n",
        "      - target_up20[t] = 1 if any High in (t+1 ... t+horizon) >= Close[t]*(1+up_thr), else 0\n",
        "      - target_dd5[t]  = 1 if any Low  in (t+1 ... t+horizon) <= Close[t]*(1+dd_thr), else 0\n",
        "    If keep_order=True:\n",
        "      - target_up_before_dd[t] = 1 if the first hit is the UP threshold, 0 if first is DOWN, -1 if none hit\n",
        "    \"\"\"\n",
        "    close = df['Close'].values\n",
        "    high  = df['High'].values\n",
        "    low   = df['Low'].values\n",
        "    n = len(df)\n",
        "\n",
        "    up_hit = np.zeros(n, dtype='int8')\n",
        "    dd_hit = np.zeros(n, dtype='int8')\n",
        "    order  = np.full(n, -1, dtype='int8')  # -1 => none\n",
        "\n",
        "    for t in range(n):\n",
        "        end = min(n, t + horizon + 1)\n",
        "        if end - t <= 1:\n",
        "            continue\n",
        "\n",
        "        entry = close[t]\n",
        "        up_th = entry * (1.0 + up_thr)\n",
        "        dd_th = entry * (1.0 + dd_thr)\n",
        "\n",
        "        hseg = high[t+1:end]\n",
        "        lseg = low[t+1:end]\n",
        "\n",
        "        up_idx = np.where(hseg >= up_th)[0]\n",
        "        dd_idx = np.where(lseg <= dd_th)[0]\n",
        "\n",
        "        hit_up = up_idx[0] if len(up_idx) else None\n",
        "        hit_dd = dd_idx[0] if len(dd_idx) else None\n",
        "\n",
        "        if hit_up is not None:\n",
        "            up_hit[t] = 1\n",
        "        if hit_dd is not None:\n",
        "            dd_hit[t] = 1\n",
        "\n",
        "        if keep_order:\n",
        "            if hit_up is None and hit_dd is None:\n",
        "                order[t] = -1\n",
        "            elif hit_up is None:\n",
        "                order[t] = 0\n",
        "            elif hit_dd is None:\n",
        "                order[t] = 1\n",
        "            else:\n",
        "                order[t] = 1 if hit_up < hit_dd else 0\n",
        "\n",
        "    s_up   = pd.Series(up_hit, index=df.index, name=name_up)\n",
        "    s_down = pd.Series(dd_hit, index=df.index, name=name_dd)\n",
        "    if keep_order:\n",
        "        s_ord = pd.Series(order, index=df.index, name=name_order)\n",
        "        return s_up, s_down, s_ord\n",
        "    else:\n",
        "        return s_up, s_down\n",
        "\n",
        "# ============================\n",
        "# FEATURES (ta + cruzamentos + padrões)\n",
        "# ============================\n",
        "def indicators_for_ticker(ohlcv: pd.DataFrame, shift_features: int = 1) -> pd.DataFrame:\n",
        "    close_col = 'Adj Close' if 'Adj Close' in ohlcv.columns else 'Close'\n",
        "\n",
        "    feats = ta.add_all_ta_features(\n",
        "        ohlcv.copy(),\n",
        "        open=\"Open\", high=\"High\", low=\"Low\", close=close_col, volume=\"Volume\",\n",
        "        fillna=True\n",
        "    )\n",
        "\n",
        "    # SMAs sobre o mesmo close_col\n",
        "    for avg in AVERAGES:\n",
        "        feats[f'SMA_{avg}'] = ohlcv[close_col].rolling(avg).mean()\n",
        "\n",
        "    # cruzamentos\n",
        "    for fast in AVERAGES:\n",
        "        for slow in AVERAGES:\n",
        "            if slow > fast:\n",
        "                fcol = f'SMA_{fast}'\n",
        "                scol = f'SMA_{slow}'\n",
        "                prev_f = feats[fcol].shift(1)\n",
        "                prev_s = feats[scol].shift(1)\n",
        "                crossname = f\"cross_{fast}_{slow}\"\n",
        "                cross = pd.Series(0, index=feats.index, dtype='int8')\n",
        "                cross[(feats[fcol] < feats[scol]) & (prev_f >= prev_s)] = -1\n",
        "                cross[(feats[fcol] > feats[scol]) & (prev_f <= prev_s)] = 1\n",
        "                feats[crossname] = cross\n",
        "\n",
        "    feats['pct_change'] = ohlcv[close_col].pct_change()\n",
        "\n",
        "    if shift_features > 0:\n",
        "        feats = feats.shift(shift_features)\n",
        "\n",
        "    int_cols = [c for c in feats.columns if str(c).startswith(\"cross_\")]\n",
        "    feats[int_cols] = feats[int_cols].astype('int8')\n",
        "    float_cols = [c for c in feats.columns if c not in int_cols]\n",
        "    feats[float_cols] = feats[float_cols].astype('float32')\n",
        "    return feats\n",
        "\n",
        "\n",
        "def patterns_for_ticker(ohlcv: pd.DataFrame, shift_features: int = 1) -> pd.DataFrame:\n",
        "    parts = [\n",
        "        detect_head_shoulder(ohlcv),\n",
        "        detect_multiple_tops_bottoms(ohlcv),\n",
        "        calculate_support_resistance(ohlcv),\n",
        "        detect_triangle_pattern(ohlcv),\n",
        "        detect_wedge(ohlcv),\n",
        "        detect_channel(ohlcv),\n",
        "        detect_double_top_bottom(ohlcv),\n",
        "        detect_trendline(ohlcv),\n",
        "    ]\n",
        "    P = pd.concat(parts, axis=1)\n",
        "    if shift_features > 0:\n",
        "        P = P.shift(shift_features)\n",
        "    patt_cols = [c for c in P.columns if c.endswith('pattern')]\n",
        "    P[patt_cols] = P[patt_cols].astype('int8')\n",
        "    other_cols = [c for c in P.columns if c not in patt_cols]\n",
        "    P[other_cols] = P[other_cols].astype('float32')\n",
        "    return P\n",
        "\n",
        "# ============================\n",
        "# TARGETS\n",
        "# ============================\n",
        "def make_target_path_aware(df, horizon=30, up=0.15, dd=-0.05, name='target_path'):\n",
        "    close = df['Close'].values\n",
        "    high  = df['High'].values\n",
        "    low   = df['Low'].values\n",
        "    n = len(df)\n",
        "    tgt = np.zeros(n, dtype='int8')\n",
        "    for t in range(n):\n",
        "        end = min(n, t + horizon + 1)\n",
        "        if end - t <= 1:\n",
        "            tgt[t] = 0\n",
        "            continue\n",
        "        entry = close[t]\n",
        "        up_th = entry * (1.0 + up)\n",
        "        dd_th = entry * (1.0 + dd)\n",
        "        hseg = high[t+1:end]\n",
        "        lseg = low[t+1:end]\n",
        "        hit_up_idx = np.where(hseg >= up_th)[0]\n",
        "        hit_dd_idx = np.where(lseg <= dd_th)[0]\n",
        "        hit_up = hit_up_idx[0] if len(hit_up_idx) else None\n",
        "        hit_dd = hit_dd_idx[0] if len(hit_dd_idx) else None\n",
        "        tgt[t] = 1 if (hit_up is not None and (hit_dd is None or hit_up < hit_dd)) else 0\n",
        "    return pd.Series(tgt, index=df.index, name=name)\n",
        "\n",
        "def make_best_entry_sale(df, horizon=30):\n",
        "    low = df['Low'].values\n",
        "    high = df['High'].values\n",
        "    n = len(df)\n",
        "    best_entry = np.empty(n, dtype='float32')\n",
        "    best_sale  = np.empty(n, dtype='float32')\n",
        "    for t in range(n):\n",
        "        end = min(n, t + horizon + 1)\n",
        "        window_low = low[t:end]\n",
        "        window_high = high[t:end]\n",
        "        best_entry[t] = float(np.nanmin(window_low))\n",
        "        best_sale[t]  = float(np.nanmax(window_high))\n",
        "    s_entry = pd.Series(best_entry, index=df.index, name='target_best_entry')\n",
        "    s_sale  = pd.Series(best_sale,  index=df.index, name='target_best_sale')\n",
        "    return s_entry, s_sale\n",
        "\n",
        "from sklearn.feature_selection import mutual_info_classif\n",
        "from sklearn.utils import check_random_state\n",
        "\n",
        "# ============================\n",
        "# Feature reduction helpers\n",
        "# ============================\n",
        "def _is_discrete_series(colname: str) -> bool:\n",
        "    # treat crosses and pattern flags as discrete\n",
        "    return colname.startswith(\"cross_\") or colname.endswith(\"pattern\")\n",
        "\n",
        "def _drop_near_constant(df_tk: pd.DataFrame, var_thr: float = 1e-12):\n",
        "    variances = df_tk.var(axis=0).astype(float)\n",
        "    keep = variances > var_thr\n",
        "    return df_tk.loc[:, keep], keep.index[keep].tolist()\n",
        "\n",
        "def _mi_rank_per_ticker(X_tk: pd.DataFrame, y_up: pd.Series, y_dd: pd.Series,\n",
        "                        random_state=42):\n",
        "    \"\"\"\n",
        "    Compute MI vs both targets; take max(MI_up, MI_dd) per feature.\n",
        "    \"\"\"\n",
        "    # mask discrete\n",
        "    cols = X_tk.columns.tolist()\n",
        "    discrete_mask = np.array([_is_discrete_series(c) for c in cols], dtype=bool)\n",
        "\n",
        "    # y must be 1D arrays\n",
        "    y_up_arr = y_up.astype('int8').values\n",
        "    y_dd_arr = y_dd.astype('int8').values\n",
        "\n",
        "    rs = check_random_state(random_state)\n",
        "    # MI can fail on constant features; ensure X already filtered\n",
        "    mi_up = mutual_info_classif(X_tk.values, y_up_arr,\n",
        "                                discrete_features=discrete_mask,\n",
        "                                random_state=rs)\n",
        "    mi_dd = mutual_info_classif(X_tk.values, y_dd_arr,\n",
        "                                discrete_features=discrete_mask,\n",
        "                                random_state=rs)\n",
        "    mi = np.maximum(mi_up, mi_dd)\n",
        "    mi_s = pd.Series(mi, index=cols).sort_values(ascending=False)\n",
        "    return mi_s\n",
        "\n",
        "def _greedy_cor_filter(X_tk: pd.DataFrame, ranking: pd.Series,\n",
        "                       corr_thr: float = 0.995):\n",
        "    \"\"\"\n",
        "    Keep features in order of 'ranking' (desc), discard any that\n",
        "    correlate (|r| >= corr_thr) with a feature already kept.\n",
        "    \"\"\"\n",
        "    if X_tk.shape[1] <= 1:\n",
        "        return X_tk.columns.tolist()\n",
        "\n",
        "    ordered = [c for c in ranking.index if c in X_tk.columns]\n",
        "    keep = []\n",
        "    # precompute correlation in chunks to save time\n",
        "    # Pearson on normalized data\n",
        "    Z = (X_tk - X_tk.mean()) / (X_tk.std(ddof=0) + 1e-12)\n",
        "\n",
        "    for c in ordered:\n",
        "        if not keep:\n",
        "            keep.append(c)\n",
        "            continue\n",
        "        # correlate c with kept\n",
        "        r = Z[keep].T.dot(Z[c]) / (len(Z) - 1)\n",
        "        max_abs_r = np.abs(r.values).max()\n",
        "        if not np.isfinite(max_abs_r) or max_abs_r < corr_thr:\n",
        "            keep.append(c)\n",
        "    return keep\n",
        "\n",
        "from sklearn.feature_selection import mutual_info_classif\n",
        "from sklearn.utils import check_random_state\n",
        "\n",
        "from sklearn.feature_selection import mutual_info_classif\n",
        "from sklearn.utils import check_random_state\n",
        "\n",
        "def reduce_features_automatic(\n",
        "    X: pd.DataFrame,\n",
        "    y_up: pd.DataFrame,\n",
        "    y_dd: pd.DataFrame,\n",
        "    top_fraction: float = 0.35,\n",
        "    min_keep: int = 48,\n",
        "    var_thr: float | None = None,     # <<< added back\n",
        "    corr_thr: float = 0.995,\n",
        "    always_keep_prefixes=(\"pct_change\",\"SMA_20\",\"SMA_50\",\"SMA_100\",\"tri_\",\"sr_\"),\n",
        "    verbose: bool = True,\n",
        "):\n",
        "    \"\"\"\n",
        "    Robust per-ticker reduction:\n",
        "      - drop constants (nunique > 1) and optionally low-variance (<= var_thr)\n",
        "      - MI vs both targets; fallback to variance if MI is flat/constant\n",
        "      - greedy correlation de-dup; pad back to min_keep\n",
        "    \"\"\"\n",
        "    if not isinstance(X.columns, pd.MultiIndex):\n",
        "        raise ValueError(\"X must use MultiIndex columns=(feature, ticker).\")\n",
        "\n",
        "    tickers = np.unique(X.columns.get_level_values(1))\n",
        "    kept_cols = []\n",
        "    before_cnt = X.shape[1]\n",
        "    rs = check_random_state(42)\n",
        "\n",
        "    up_tk_set = set(y_up.columns.get_level_values(1))\n",
        "    dd_tk_set = set(y_dd.columns.get_level_values(1))\n",
        "\n",
        "    for tk in tickers:\n",
        "        X_tk = X.xs(tk, level=1, axis=1).copy()\n",
        "\n",
        "        # numeric only + ensure no NaN/Inf\n",
        "        X_tk = X_tk.apply(pd.to_numeric, errors='coerce').replace([np.inf,-np.inf], np.nan).fillna(0.0)\n",
        "\n",
        "        # drop constants\n",
        "        nunique = X_tk.nunique(dropna=False)\n",
        "        X_tk_nc = X_tk.loc[:, nunique > 1]\n",
        "\n",
        "        # optional variance threshold\n",
        "        if var_thr is not None and X_tk_nc.shape[1] > 0:\n",
        "            variances = X_tk_nc.var().astype(float)\n",
        "            X_tk_nc = X_tk_nc.loc[:, variances > var_thr]\n",
        "\n",
        "        if X_tk_nc.shape[1] == 0:\n",
        "            base = [c for c in X_tk.columns if any(str(c).startswith(p) for p in always_keep_prefixes)]\n",
        "            base = base[:min_keep] if base else X_tk.columns[:min_keep].tolist()\n",
        "            kept_cols.extend([(c, tk) for c in base])\n",
        "            continue\n",
        "\n",
        "        # if labels missing for ticker, keep top variance\n",
        "        if (tk not in up_tk_set) or (tk not in dd_tk_set):\n",
        "            var_rank = X_tk_nc.var().sort_values(ascending=False)\n",
        "            base = var_rank.index[:min(min_keep, len(var_rank))].tolist()\n",
        "            kept_cols.extend([(c, tk) for c in base])\n",
        "            continue\n",
        "\n",
        "        y_up_tk = y_up.xs(tk, level=1, axis=1).iloc[:,0].astype('int8')\n",
        "        y_dd_tk = y_dd.xs(tk, level=1, axis=1).iloc[:,0].astype('int8')\n",
        "\n",
        "        cols = X_tk_nc.columns.tolist()\n",
        "        discrete_mask = np.array([str(c).startswith('cross_') or str(c).endswith('pattern') for c in cols], dtype=bool)\n",
        "\n",
        "        def safe_mi(Xarr, yarr):\n",
        "            if np.unique(yarr).size < 2:\n",
        "                return np.zeros(Xarr.shape[1], dtype=float)\n",
        "            try:\n",
        "                return mutual_info_classif(Xarr, yarr, discrete_features=discrete_mask, random_state=rs)\n",
        "            except Exception:\n",
        "                return np.zeros(Xarr.shape[1], dtype=float)\n",
        "\n",
        "        mi_up = safe_mi(X_tk_nc.values, y_up_tk.values)\n",
        "        mi_dd = safe_mi(X_tk_nc.values, y_dd_tk.values)\n",
        "        mi = np.maximum(mi_up, mi_dd)\n",
        "\n",
        "        mi_rank = pd.Series(mi, index=cols).sort_values(ascending=False)\n",
        "        k_top = min(len(mi_rank), max(min_keep, int(np.ceil(len(mi_rank) * top_fraction))))\n",
        "        top_feats = mi_rank.index[:k_top].tolist()\n",
        "\n",
        "        # ensure interpretable anchors\n",
        "        for pref in always_keep_prefixes:\n",
        "            top_feats.extend([c for c in X_tk_nc.columns if str(c).startswith(pref)])\n",
        "        # de-dup order\n",
        "        seen = set()\n",
        "        top_feats = [c for c in top_feats if not (c in seen or seen.add(c))]\n",
        "\n",
        "        # fallback if MI flat\n",
        "        if len(top_feats) == 0 or (mi_rank.iloc[0] == 0 and mi_rank.sum() == 0):\n",
        "            var_rank = X_tk_nc.var().sort_values(ascending=False)\n",
        "            top_feats = var_rank.index[:min(min_keep, len(var_rank))].tolist()\n",
        "\n",
        "        # greedy correlation de-dup\n",
        "        X_top = X_tk_nc[top_feats]\n",
        "        Z = (X_top - X_top.mean()) / (X_top.std(ddof=0) + 1e-12)\n",
        "        keep = []\n",
        "        for c in X_top.columns:\n",
        "            if not keep:\n",
        "                keep.append(c); continue\n",
        "            r = Z[keep].T.dot(Z[c]) / max(1, (len(Z) - 1))\n",
        "            max_abs_r = np.abs(r.values).max() if hasattr(r, \"values\") else float(np.abs(r).max())\n",
        "            if not np.isfinite(max_abs_r) or max_abs_r < corr_thr:\n",
        "                keep.append(c)\n",
        "\n",
        "        # pad to min_keep\n",
        "        if len(keep) < min_keep:\n",
        "            for c in top_feats:\n",
        "                if c not in keep:\n",
        "                    keep.append(c)\n",
        "                    if len(keep) >= min_keep:\n",
        "                        break\n",
        "\n",
        "        kept_cols.extend([(c, tk) for c in keep])\n",
        "\n",
        "    if len(kept_cols) == 0:\n",
        "        for tk in tickers:\n",
        "            cols_tk = X.xs(tk, level=1, axis=1).columns[:min_keep].tolist()\n",
        "            kept_cols.extend([(c, tk) for c in cols_tk])\n",
        "\n",
        "    kept_cols = pd.MultiIndex.from_tuples(kept_cols, names=X.columns.names)\n",
        "    X_red = X.loc[:, kept_cols].copy()\n",
        "\n",
        "    # compact dtypes\n",
        "    X_red = cast_int8_multi(X_red, prefixes=(\"cross_\",), suffixes=(\"pattern\",))\n",
        "    other0 = [c for c in X_red.columns.get_level_values(0)\n",
        "              if not (str(c).startswith(\"cross_\") or str(c).endswith(\"pattern\"))]\n",
        "    if other0:\n",
        "        X_red.loc[:, (other0, slice(None))] = X_red.loc[:, (other0, slice(None))].astype('float32')\n",
        "\n",
        "    if verbose:\n",
        "        after_cnt = X_red.shape[1]\n",
        "        print(f\"[Feature reduction] columns: {before_cnt} → {after_cnt} ({100.0*after_cnt/before_cnt:.1f}% kept)\")\n",
        "    return X_red\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ============================\n",
        "# Construção por ticker\n",
        "# ============================\n",
        "feat_frames = []\n",
        "tgt_frames  = []\n",
        "\n",
        "print(\"Gerando features e targets por ticker...\")\n",
        "from collections import Counter\n",
        "\n",
        "feat_frames = []\n",
        "tgt_frames  = []\n",
        "skip_reasons = Counter()\n",
        "\n",
        "print(\"Gerando features e targets por ticker...\")\n",
        "for tk in tqdm(tickers):\n",
        "    try:\n",
        "        ohlcv = data.xs(tk, level=1, axis=1).copy()\n",
        "\n",
        "        # ✅ Require only what you truly need for features/targets\n",
        "        # Targets need High/Low; indicators need a close; SMAs may use Open but not required\n",
        "        have = set(ohlcv.columns.astype(str))\n",
        "        req = {'Close','High','Low'}   # do NOT require 'Adj Close' or 'Volume' here\n",
        "        if not req.issubset(have):\n",
        "            skip_reasons['missing_basic_ohlc'] += 1\n",
        "            continue\n",
        "\n",
        "        # Fallbacks to avoid skipping indices/FX/crypto\n",
        "        if 'Adj Close' not in have:\n",
        "            ohlcv['Adj Close'] = ohlcv['Close'].astype('float32')\n",
        "        if 'Open' not in have:\n",
        "            ohlcv['Open'] = ohlcv['Close'].astype('float32')\n",
        "        if 'Volume' not in have:\n",
        "            ohlcv['Volume'] = 0.0\n",
        "\n",
        "        # Build features\n",
        "        feats = indicators_for_ticker(ohlcv, shift_features=SHIFT_FEATURES)\n",
        "        pats  = patterns_for_ticker(ohlcv, shift_features=SHIFT_FEATURES)\n",
        "        if feats is None or feats.shape[1] == 0:\n",
        "            skip_reasons['empty_feats'] += 1\n",
        "            continue\n",
        "        X_tk  = pd.concat([feats, pats], axis=1)\n",
        "\n",
        "        # Fill & attach ticker level\n",
        "        X_tk = fill_100pct(X_tk, allow_bfill=ALLOW_BFILL_EXOGENOUS)\n",
        "        if X_tk.shape[1] == 0:\n",
        "            skip_reasons['empty_after_fill'] += 1\n",
        "            continue\n",
        "\n",
        "        X_tk.columns = pd.MultiIndex.from_product([X_tk.columns, [tk]])\n",
        "        feat_frames.append(X_tk)\n",
        "\n",
        "        # Targets (split up/down)\n",
        "        y_up20, y_dd5 = make_targets_up_down(\n",
        "            ohlcv, horizon=HORIZON, up_thr=0.20, dd_thr=-0.05, keep_order=False\n",
        "        )\n",
        "        y_up20.name = ('target_up20', tk)\n",
        "        y_dd5.name  = ('target_dd5',  tk)\n",
        "        tgt_frames.extend([y_up20, y_dd5])\n",
        "\n",
        "        # Best entry/sale (keep if you use downstream)\n",
        "        y_entry, y_sale = make_best_entry_sale(ohlcv, horizon=HORIZON)\n",
        "        y_entry.name = ('target_best_entry', tk)\n",
        "        y_sale.name  = ('target_best_sale',  tk)\n",
        "        tgt_frames.extend([y_entry, y_sale])\n",
        "\n",
        "    except Exception as e:\n",
        "        # don’t crash the whole build for one bad ticker\n",
        "        skip_reasons[f'exception:{type(e).__name__}'] += 1\n",
        "        # uncomment to inspect:\n",
        "        # print(f\"[{tk}] skipped due to {type(e).__name__}: {e}\")\n",
        "        continue\n",
        "\n",
        "# Safety + diagnostics\n",
        "if len(feat_frames) == 0:\n",
        "    raise RuntimeError(f\"No features built for any ticker. Skip reasons: {dict(skip_reasons)}\")\n",
        "else:\n",
        "    print(\"Tickers processados:\", len(feat_frames), \"| Motivos de skip:\", dict(skip_reasons))\n",
        "\n",
        "# Concat globais\n",
        "X = pd.concat(feat_frames, axis=1).sort_index()\n",
        "y = pd.concat(tgt_frames,  axis=1).sort_index()\n",
        "\n",
        "# Cast consistente (atualizado p/ novos targets)\n",
        "X = cast_int8_multi(X, prefixes=(\"cross_\",), suffixes=(\"pattern\",))\n",
        "other0 = [c for c in X.columns.get_level_values(0)\n",
        "          if not (str(c).startswith(\"cross_\") or str(c).endswith(\"pattern\"))]\n",
        "if other0:\n",
        "    X.loc[:, (other0, slice(None))] = X.loc[:, (other0, slice(None))].astype('float32')\n",
        "\n",
        "for tname in ('target_up20','target_dd5'):\n",
        "    if tname in y.columns.get_level_values(0):\n",
        "        y.loc[:, (tname, slice(None))] = y.loc[:, (tname, slice(None))].astype('int8')\n",
        "for tname in ('target_best_entry','target_best_sale'):\n",
        "    if tname in y.columns.get_level_values(0):\n",
        "        y.loc[:, (tname, slice(None))] = y.loc[:, (tname, slice(None))].astype('float32')\n",
        "\n",
        "\n",
        "# Garantir 100% preenchido (inf/NaN) globalmente (features já estão ok; segurança adicional)\n",
        "X = fill_100pct(X, allow_bfill=ALLOW_BFILL_EXOGENOUS)\n",
        "y = fill_100pct(y, allow_bfill=True)\n",
        "\n",
        "# Verificações finais\n",
        "assert not X.isna().any().any(), \"Ainda há NaN em X após preenchimento!\"\n",
        "assert not y.isna().any().any(), \"Ainda há NaN em y após preenchimento!\"\n",
        "\n",
        "# ============================\n",
        "# Saída única combinada\n",
        "# ============================\n",
        "DATASET = pd.concat([X, y], axis=1).sort_index()\n",
        "# Segurança final (caso algum merge crie lacunas):\n",
        "DATASET = fill_100pct(DATASET, allow_bfill=ALLOW_BFILL_EXOGENOUS)\n",
        "\n",
        "# Sanidade: sem NaN\n",
        "assert not DATASET.isna().any().any(), \"Ainda há NaN no dataset final!\"\n",
        "\n",
        "# ============================\n",
        "# Feature reduction (per ticker, MI vs targets)\n",
        "# ============================\n",
        "# y_up and y_dd views (ensure they exist)\n",
        "y_up = y.loc[:, y.columns.get_level_values(0) == 'target_up20']\n",
        "y_dd = y.loc[:, y.columns.get_level_values(0) == 'target_dd5']\n",
        "\n",
        "X_reduced = reduce_features_automatic(\n",
        "    X, y_up, y_dd,\n",
        "    top_fraction=0.85,   # pega ~85% por MI antes de deduplicar\n",
        "    min_keep=96,         # garanta pelo menos ~100 por ticker (se existirem)\n",
        "    var_thr=None,        # não remova por variância agora\n",
        "    corr_thr=0.9995,     # só remove quase idênticos\n",
        "    always_keep_prefixes=(\"pct_change\",\"SMA_\",\"tri_\",\"sr_\"),\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "# ============================\n",
        "# Output (full and reduced)\n",
        "# ============================\n",
        "DATASET_FULL = pd.concat([X, y], axis=1).sort_index()\n",
        "DATASET_FULL = fill_100pct(DATASET_FULL, allow_bfill=ALLOW_BFILL_EXOGENOUS)\n",
        "assert not DATASET_FULL.isna().any().any(), \"NaN in full dataset!\"\n",
        "\n",
        "DATASET_REDUCED = pd.concat([X_reduced, y], axis=1).sort_index()\n",
        "DATASET_REDUCED = fill_100pct(DATASET_REDUCED, allow_bfill=ALLOW_BFILL_EXOGENOUS)\n",
        "assert not DATASET_REDUCED.isna().any().any(), \"NaN in reduced dataset!\"\n",
        "\n",
        "if SAVE_PARQUET:\n",
        "    DATASET_FULL.to_parquet(OUTPUT_PATH, compression=\"snappy\")\n",
        "    OUT_REDUCED = OUTPUT_PATH.replace(\".parquet\", \"_reduced.parquet\")\n",
        "    DATASET_REDUCED.to_parquet(OUT_REDUCED, compression=\"snappy\")\n",
        "    print(f\"Saved FULL:     {OUTPUT_PATH}  shape={DATASET_FULL.shape}\")\n",
        "    print(f\"Saved REDUCED:  {OUT_REDUCED}  shape={DATASET_REDUCED.shape}\")\n",
        "else:\n",
        "    print(\"FULL:\", DATASET_FULL.shape, \" | REDUCED:\", DATASET_REDUCED.shape)\n",
        "\n",
        "print(\"X full:\", X.shape)\n",
        "print(\"y:\", y.shape)\n",
        "print(\"X_reduced:\", X_reduced.shape)\n",
        "\n",
        "# Per-ticker kept counts\n",
        "kept_counts = pd.Series(dict(\n",
        "    (tk, X_reduced.xs(tk, level=1, axis=1).shape[1])\n",
        "    for tk in np.unique(X_reduced.columns.get_level_values(1))\n",
        ")).sort_values(ascending=True)\n",
        "print(\"Min/median/max kept per ticker:\", kept_counts.min(), kept_counts.median(), kept_counts.max())\n",
        "\n",
        "processed = np.unique(X.columns.get_level_values(1))\n",
        "print(\"Processed tickers:\", len(processed))\n",
        "missing = sorted(set(tickers) - set(processed))\n",
        "print(\"Missing tickers:\", len(missing))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "-MlRcKH_z8GQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405
        },
        "outputId": "c2b0ebef-bba9-458c-f81b-21f291d5520e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           trend_visual_ichimoku_b volatility_dch trend_ichimoku_b  \\\n",
              "                          ABEV3.SA       ABEV3.SA         ABEV3.SA   \n",
              "Date                                                                 \n",
              "2025-12-27               12.204355          13.82        13.092719   \n",
              "2025-12-28               12.360700          13.82        13.092719   \n",
              "2025-12-29               12.365438          13.87        13.117719   \n",
              "2025-12-30               12.365438          14.09        13.227719   \n",
              "2025-12-31               12.441240          14.09        13.246670   \n",
              "\n",
              "           volatility_dcl    volume_obv trend_ichimoku_base   volume_nvi  \\\n",
              "                 ABEV3.SA      ABEV3.SA            ABEV3.SA     ABEV3.SA   \n",
              "Date                                                                       \n",
              "2025-12-27      12.450716  3.177428e+10           13.135358  2450.013916   \n",
              "2025-12-28      12.450716  3.180340e+10           13.135358  2450.013916   \n",
              "2025-12-29      12.450716  3.182370e+10           13.160358  2476.799805   \n",
              "2025-12-30      12.716028  3.179840e+10           13.270358  2476.799805   \n",
              "2025-12-31      13.000000  3.182370e+10           13.270358  2476.799805   \n",
              "\n",
              "           trend_resistance2 mtb_close_roll_min trend_psar_up  ...  \\\n",
              "                    ABEV3.SA           ABEV3.SA      ABEV3.SA  ...   \n",
              "Date                                                           ...   \n",
              "2025-12-27         13.470000              13.47     12.933102  ...   \n",
              "2025-12-28         13.720000              13.72     12.986316  ...   \n",
              "2025-12-29         13.720000              13.72     13.036337  ...   \n",
              "2025-12-30         13.720000              13.72     13.103030  ...   \n",
              "2025-12-31         13.849999              13.86     13.201727  ...   \n",
              "\n",
              "           target_best_entry target_best_sale target_up20 target_dd5  \\\n",
              "                       ^JKSE            ^JKSE       ^N225      ^N225   \n",
              "Date                                                                   \n",
              "2025-12-27       8525.100586      8663.667969           0          0   \n",
              "2025-12-28       8525.100586      8663.667969           0          0   \n",
              "2025-12-29       8545.721680      8663.667969           0          0   \n",
              "2025-12-30       8584.865234      8663.667969           0          0   \n",
              "2025-12-31       8584.865234      8663.667969           0          0   \n",
              "\n",
              "           target_best_entry target_best_sale target_up20 target_dd5  \\\n",
              "                       ^N225            ^N225        ^SSE       ^SSE   \n",
              "Date                                                                   \n",
              "2025-12-27       50198.96875     50941.890625           1          1   \n",
              "2025-12-28       50198.96875     50941.890625           1          1   \n",
              "2025-12-29       50198.96875     50707.230469           1          1   \n",
              "2025-12-30       50198.96875     50534.640625           1          1   \n",
              "2025-12-31       50198.96875     50534.640625           0          0   \n",
              "\n",
              "           target_best_entry target_best_sale  \n",
              "                        ^SSE             ^SSE  \n",
              "Date                                           \n",
              "2025-12-27        100.029999       149.509995  \n",
              "2025-12-28        100.029999       149.509995  \n",
              "2025-12-29        100.029999       149.509995  \n",
              "2025-12-30        100.029999       149.509995  \n",
              "2025-12-31        100.029999       149.509995  \n",
              "\n",
              "[5 rows x 14864 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2a4d8ef6-673c-4317-9323-2cf446f632fc\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr:last-of-type th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>trend_visual_ichimoku_b</th>\n",
              "      <th>volatility_dch</th>\n",
              "      <th>trend_ichimoku_b</th>\n",
              "      <th>volatility_dcl</th>\n",
              "      <th>volume_obv</th>\n",
              "      <th>trend_ichimoku_base</th>\n",
              "      <th>volume_nvi</th>\n",
              "      <th>trend_resistance2</th>\n",
              "      <th>mtb_close_roll_min</th>\n",
              "      <th>trend_psar_up</th>\n",
              "      <th>...</th>\n",
              "      <th>target_best_entry</th>\n",
              "      <th>target_best_sale</th>\n",
              "      <th>target_up20</th>\n",
              "      <th>target_dd5</th>\n",
              "      <th>target_best_entry</th>\n",
              "      <th>target_best_sale</th>\n",
              "      <th>target_up20</th>\n",
              "      <th>target_dd5</th>\n",
              "      <th>target_best_entry</th>\n",
              "      <th>target_best_sale</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>ABEV3.SA</th>\n",
              "      <th>ABEV3.SA</th>\n",
              "      <th>ABEV3.SA</th>\n",
              "      <th>ABEV3.SA</th>\n",
              "      <th>ABEV3.SA</th>\n",
              "      <th>ABEV3.SA</th>\n",
              "      <th>ABEV3.SA</th>\n",
              "      <th>ABEV3.SA</th>\n",
              "      <th>ABEV3.SA</th>\n",
              "      <th>ABEV3.SA</th>\n",
              "      <th>...</th>\n",
              "      <th>^JKSE</th>\n",
              "      <th>^JKSE</th>\n",
              "      <th>^N225</th>\n",
              "      <th>^N225</th>\n",
              "      <th>^N225</th>\n",
              "      <th>^N225</th>\n",
              "      <th>^SSE</th>\n",
              "      <th>^SSE</th>\n",
              "      <th>^SSE</th>\n",
              "      <th>^SSE</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2025-12-27</th>\n",
              "      <td>12.204355</td>\n",
              "      <td>13.82</td>\n",
              "      <td>13.092719</td>\n",
              "      <td>12.450716</td>\n",
              "      <td>3.177428e+10</td>\n",
              "      <td>13.135358</td>\n",
              "      <td>2450.013916</td>\n",
              "      <td>13.470000</td>\n",
              "      <td>13.47</td>\n",
              "      <td>12.933102</td>\n",
              "      <td>...</td>\n",
              "      <td>8525.100586</td>\n",
              "      <td>8663.667969</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>50198.96875</td>\n",
              "      <td>50941.890625</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>100.029999</td>\n",
              "      <td>149.509995</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2025-12-28</th>\n",
              "      <td>12.360700</td>\n",
              "      <td>13.82</td>\n",
              "      <td>13.092719</td>\n",
              "      <td>12.450716</td>\n",
              "      <td>3.180340e+10</td>\n",
              "      <td>13.135358</td>\n",
              "      <td>2450.013916</td>\n",
              "      <td>13.720000</td>\n",
              "      <td>13.72</td>\n",
              "      <td>12.986316</td>\n",
              "      <td>...</td>\n",
              "      <td>8525.100586</td>\n",
              "      <td>8663.667969</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>50198.96875</td>\n",
              "      <td>50941.890625</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>100.029999</td>\n",
              "      <td>149.509995</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2025-12-29</th>\n",
              "      <td>12.365438</td>\n",
              "      <td>13.87</td>\n",
              "      <td>13.117719</td>\n",
              "      <td>12.450716</td>\n",
              "      <td>3.182370e+10</td>\n",
              "      <td>13.160358</td>\n",
              "      <td>2476.799805</td>\n",
              "      <td>13.720000</td>\n",
              "      <td>13.72</td>\n",
              "      <td>13.036337</td>\n",
              "      <td>...</td>\n",
              "      <td>8545.721680</td>\n",
              "      <td>8663.667969</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>50198.96875</td>\n",
              "      <td>50707.230469</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>100.029999</td>\n",
              "      <td>149.509995</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2025-12-30</th>\n",
              "      <td>12.365438</td>\n",
              "      <td>14.09</td>\n",
              "      <td>13.227719</td>\n",
              "      <td>12.716028</td>\n",
              "      <td>3.179840e+10</td>\n",
              "      <td>13.270358</td>\n",
              "      <td>2476.799805</td>\n",
              "      <td>13.720000</td>\n",
              "      <td>13.72</td>\n",
              "      <td>13.103030</td>\n",
              "      <td>...</td>\n",
              "      <td>8584.865234</td>\n",
              "      <td>8663.667969</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>50198.96875</td>\n",
              "      <td>50534.640625</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>100.029999</td>\n",
              "      <td>149.509995</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2025-12-31</th>\n",
              "      <td>12.441240</td>\n",
              "      <td>14.09</td>\n",
              "      <td>13.246670</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>3.182370e+10</td>\n",
              "      <td>13.270358</td>\n",
              "      <td>2476.799805</td>\n",
              "      <td>13.849999</td>\n",
              "      <td>13.86</td>\n",
              "      <td>13.201727</td>\n",
              "      <td>...</td>\n",
              "      <td>8584.865234</td>\n",
              "      <td>8663.667969</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>50198.96875</td>\n",
              "      <td>50534.640625</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>100.029999</td>\n",
              "      <td>149.509995</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 14864 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2a4d8ef6-673c-4317-9323-2cf446f632fc')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2a4d8ef6-673c-4317-9323-2cf446f632fc button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2a4d8ef6-673c-4317-9323-2cf446f632fc');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-969183c6-2338-4340-860b-d39a0ce66cd1\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-969183c6-2338-4340-860b-d39a0ce66cd1')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-969183c6-2338-4340-860b-d39a0ce66cd1 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "DATASET_REDUCED.tail()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNZO7pKTvDhPWElm6Wfz+xT",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}